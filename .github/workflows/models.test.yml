name: CI

on:
  push:
  pull_request:

permissions:
  contents: read      # needed for checkout + artifacts
  models: read        # needed for GitHub Models API

jobs:
  test:
    runs-on: ubuntu-latest
    env:
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}


    steps:
      - name: Checkout repositorys
        uses: actions/checkout@v4

      - name: Sest up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt || true
          pip install openai pytest python-dotenv colorama

      - name: Run tests
        run: pytest -q

  call-model:
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    env:
      GIT_TOKEN: ${{ secrets.GIT_TOKEN }}

    steps:
      - name: Call AI model and save result

        run: |
          RESPONSE=$(curl "https://models.github.ai/inference/chat/completions" \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer $GITHUB_TOKEN" \
            -d '{
              "messages": [
                {
                  "role": "user",
                  "content": "explain how to use github models api in ci cd pipeline"
                }
              ],
              "model": "openai/gpt-4o"
            }')

          echo "$RESPONSE" > raw_response.json

          # Extract the message content (OpenAI-style chat/completions response)
          echo "$RESPONSE" | jq -r '.choices[0].message.content' > ai_output.txt

      - name: Upload result as artifact
        uses: actions/upload-artifact@v4
        with:
          name: ai-output
          path: |
            raw_response.json
            ai_output.txt
