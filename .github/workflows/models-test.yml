name: CI

on:
  push:
  pull_request:

permissions:
  models: read

jobs:
  test:
    runs-on: ubuntu-latest
    env:
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt || true
          pip install openai pytest python-dotenv colorama

      - name: Run tests
        run: pytest -q

  call-model:
  runs-on: ubuntu-latest

  steps:
    - name: Call AI model and save result
    - run: |
        RESPONSE=$(curl "https://models.github.ai/inference/chat/completions" \
          -H "Content-Type: application/json" \
          -H "Authorization: Bearer $GITHUB_TOKEN" \
          -d '{
            "messages": [
              {
                "role": "user",
                "content": "Explain the concept of recursion."
              }
            ],
            "model": "openai/gpt-4o"
          }')

        echo "$RESPONSE" > raw_response.json

        # If the response format is OpenAI-like, extract the message content text
        # (you may need jq installed; it's available by default on GH runners)
        echo "$RESPONSE" | jq -r '.choices[0].message.content[0].text' > ai_output.txt

    - name: Upload result as artifact
      uses: actions/upload-artifact@v4
      with:
        name: ai-output
        path: |
          raw_response.json
          ai_output.txt
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}